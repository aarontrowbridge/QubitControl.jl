\documentclass{article}

\usepackage[bookmarks]{hyperref}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{physics}
\usepackage{authblk}

\usepackage[a4paper, margin=1.25in, footskip=0.25in]{geometry}

\newcommand{\QP}{\text{QP}}
\newcommand{\isopsi}{\tilde \psi}
\newcommand{\minimize}[1]{\underset{#1}{\text{minimize}}}
\newcommand{\st}{\text{subject to}}

\title{\LARGE \textsc{
  Direct Collocation \\ for \\ Quantum Optimal Control 
}}

\author[1]{Aaron Trowbridge}
\author[2]{Aditya Bhardwaj}
\author[2]{Kevin He}

\affil[1]{Robotics Exploration Lab, Carnegie Mellon University}
\affil[2]{Schuster Lab, Stanford University}



\date{}

% \setcounter{section}{-1}

% \setlength\parindent{0pt}

\begin{document}
\maketitle

\pagenumbering{roman}

\begin{abstract}
  We present an adaptation of the \textit{direct collocation} trajectory optimization method for solving problems in quantum optimal control (QOC).  This approach addresses several limitations of standard methods, including the ability to solve minimum time problems, a crucial objective for realizing high-performance quantum computers.  We demonstrate that this approach leads to improved performance on simulated systems as well as on nascent hardware devices, compared to other existing methods.  To the best of our knowledge, this is the first time that direct collocation, which is commonplace in the field of robotic control, has been applied to QOC. 
\end{abstract}

% \newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction}
Controlling quantum systems is in principle the problem of optimizing over the space of quantum state trajectories given the ability to control, over an interval of time, certain terms in the time-dependent Hamiltonian describing the system. We will consider $n$-dimensional quantum systems with time-dependent Hamiltonians of the form

\begin{equation}
  H(\vb{a}(t), t) = H_0 + \sum_i a^i(t) H_i,
\end{equation}

\noindent
where $t \in [0, T]$, $\vb{a}(t) \in \mathbb{R}^m$ is the control trajectory, referred to as the \textit{pulse}, $H_0$ is the system's \textit{drift} term, and $H_i$ are the \textit{drive} terms.  

The field of optimal control, which has its origins in space systems and robotics, has produced, especially in recent years, a large body of sophisticated methods for solving control problems fundamentally identical to the problems posed in QOC.  However, many of these methods have not seemed to have been adopted by those (primarily physicists) working on control problems for quantum systems. This work aims to bridge the gap between robotic control and quantum control, and in so doing to provide a new perspective on the problem of quantum control. 

\subsection{Types of Problems}
There are typically three flavors of QOC problems, corresponding to three types of states:

\begin{enumerate}
  \item \textit{Pure quantum states} $\psi(t)$: Minimize the infidelity between the final state $\psi(T)$ and the goal state $\psi_{\text{goal}}$:

  \begin{equation}
    \ell(\psi(T)) = 1 - \abs{\bra{\psi(T)} \ket{\psi_{\text{goal}}}}^2
  \end{equation}

  Where $\psi(0) = \psi_{\text{init}}$ and $\psi(t)$ satisfies the Schr\"oedinger equation $\dot \psi = -i H(\vb{a}(t), t) \psi$.

  \item \textit{Unitary operators} $U(t)$: Minimize the infidelity or trace distance between the final unitary $U(T)$ and the desired final unitary $U_{\text{goal}}$: respectively,
  
  \begin{equation}
    \ell(U(T)) = 1 - \qty(\text{tr}\sqrt{U(T)^\dagger U_{\text{goal}}})^2 
    \quad \text{or} \quad
    \ell(U(T)) = \frac{1}{2} \norm{U(T) - U_{\text{goal}}}_{\text{tr}},
  \end{equation}

  Here $U(0) = I$ and $U(t)$ also satisfies the Schr\"oedinger equation $\dot U = -i H(\vb{a}(t), t) U$.
  \item \textit{Mixed quantum states} or \textit{density matrices} $\rho(t)$:  Minimize the infidelity or trace distance between the final state $\rho(T)$ and the goal state $\rho_{\text{goal}}$: respectively,

  \begin{equation}
    \ell(\rho(T)) = 1 - \qty(\text{tr}\sqrt{\rho(T) \rho_{\text{goal}}})^2 
    \quad \text{or} \quad
    \ell(\rho(T)) = \frac{1}{2} \norm{\rho(T) - \rho_{\text{goal}}}_{\text{tr}}.
  \end{equation}

  Here $\rho(0) = \rho_{\text{init}}$ and $\rho(t)$ satisfies the von Neumann equation $\dot \rho = -i \qty[H(\vb{a}(t), t), \rho]$. 
  
\end{enumerate}

\noindent
\textbf{Remark:} In this paper, for simplicity, we will focus on the first type of problem, and just consider the case of optimizing a single pure quantum state $\psi(t)$ --- all methods discussed apply to the other two types of problems as well.

\newpage
\section{Background}
In practice, to do any type of trajectory optimization it is necessary to discretize the time interval $[0, T]$ into $N$ time steps of size $\Delta t$, the states and controls at each time step are denoted $\psi_k$ and $\vb{a}_k$, respectively. Typically the following optimization is then solved to find the optimal pulse: 

\begin{align}
  \minimize{\vb{a}_{1:T-1}} \quad &J(\vb{a}_{1:T-1}) = \ell(\psi_N(\vb{a}_{1:T-1})), \\
  \st \quad &c(\vb{a}_k) \leq 0, \quad \forall k
\end{align}

\noindent
where 

\begin{equation}
  \psi_{k + 1} = \exp\qty(-i H(\vb{a}_k) \Delta t) \ \psi_k 
\end{equation}

\noindent
and $\psi_1 = \psi_{\text{init}}$.  Here, during the time interval $\Delta t$ the controls $\vb{a}_k$ are held constant, which is referred to as a \textit{zero-order hold}, and allows the dynamics to exactly take the form above. 

Current approaches for solving this problem fall into two categories: \textit{gradient-based} methods and \textit{basis function} methods.  Both of these are \textit{indirect} methods, as they optimize only over the controls $\vb{a}_{1:T-1}$, as opposed to considering both the states and controls as decision variables in what is known as \text{direct} methods. The advantages of direct methods, over indirect methods, are the main point of this paper.  Before getting to the details of direct methods we will first introduce these two current mainstream approaches to solving QOC problems.

\subsection{Gradient-Based Methods}
This method involves initializing the controls $\vb{a}_{1:T-1}$ to some initial guess, and then iteratively updating them using a gradient descent algorithm.  At each iteration is necessary to \textit{rollout} the system with the given controls (this is also referred to as a \textit{shooting method}) to get $\psi_N$ and evaluate the cost function $J(\vb{a})$ to be able to take a gradient of it and update the controls:

\begin{equation}
  \vb{a} \leftarrow \vb{a} - \beta \nabla J(\vb{a})
\end{equation}

There are efficient ways to compute this gradient, but the approach is still limited in other ways.  These include the fact that the solution is dependent on the initial guess, gradient-based methods are in general prone to falling into local minima, and it is not possible to enforce constraints on the states.

The most popular gradient-based method is known as GRAPE (GRadient Ascent Pulse Engineering), which is available through the popular QuTiP python library.  Q-CTRL also implements its own gradient-based optimization tool, which is virtually identical, is the industry standard, and is what we compare our results to in this paper.

\subsection{Gradient-Free Methods}
For this class of approaches, the key idea is to reduce the number of decision variables enough so that gradient-free optimization algorithms---e.g. the Nelder-Mead downhill simplex method---can be utilized. In the case of the popular CRAB algorithm (also implemented in QuTiP and compared against later on) this is accomplished by parameterizing the pulse by a set of basis functions.  The CRAB algorithm, specifically, utilizes a Fourier basis parameterization for each pulse component:

\begin{equation}
  a(t) = 1 + \frac{\sum_{n=1}^{N_c} b_n \sin(\omega_n t) + c_n \cos(\omega_n t)}{\lambda(t)}.
\end{equation}

\noindent
Where $N_c$ is the number of terms to \textit{chop} the series off at and $\lambda(t)$ is chosen to enforce the boundary conditions. Standard gradient-free methods can then be used to solve the new optimization problem:

\begin{equation}
  \minimize{b_{1:N_c}, c_{1:N_c}, \omega_{1:N_c}} \quad J(b_{1:N_c}, c_{1:N_c}, \omega_{1:N_c}).
\end{equation}
  


\newpage
\section{Direct Collocation}
In this section we describe \textit{direct collocation}, a direct approach to solving trajectory optimization problems.  At a high level direct collocation allows us to overcome the limitations of indirect methods by including the states as decision variables, along side the controls, at each time-step; respectively denoted $x_k$ and $u_k$.  In this formulation the dynamics---which are implicit in indirect methods, coming in during the rollout phase---are enforced as constraints between \textit{knot points} $z_k = (x_k, u_k)^\top$.  

With the dynamics enforced as constraints, numerical non-linear solvers are free to violate these constraints during intermediate points of the optimization routine, en route to satisfying them at convergence.  This capability, along with the ability to enforce constraints on the state variables, lend theoretical and empirical evidence towards the superiority of direct methods over indirect. 

\subsection{Notation}
In this section we will adopt the following (mostly) conventional control theory notation to focus on the structure of the problems  --- in the following section we will apply these methods to quantum systems.

\begin{itemize}
  \item $x$: represents the states, where $x_k \in \mathbb{R}^n$
  \item $u$: represents the controls, where $u_k \in \mathbb{R}^m$
  \item $z$: represents a knot point, where $z_k = (x_k, u_k)^\top \in \mathbb{R}^{n+m}$
\end{itemize}

\subsection{State Transfer Problems}

A core problem in trajectory optimization is the state transfer from problem, where we want to begin in an initial state, i.e. $x_1 = x_{\text{goal}}$, and find a control sequence $u_{1:N-1}$ such that $x_N$ minimizes a loss $\ell$ relative to the goal state $x_{\text{goal}}$, .  We will enforce the dynamics constraints implicitly, i.e. as $f(x_{k+1}, x_k, u_k) = 0$, for reasons of generality here, but as elucidated later, to increase computational efficiency. We can write this problem like so: 

\begin{align}
  \minimize{x, u} \quad & \ell(x_N) \\
  \st \quad & f(x_{k+1}, x_k, u_k) = 0 \\
            & x_1 = x_{\text{init}} 
\end{align}

\subsection{Free Time Problems}
If we do not know the optimal time interval in which to solve our problem, this framework allows us to easily modify our the previous problem so that the solver can find the optimal time on its own.  This is accomplished by including making each time step $\Delta t_k$ a decision variable and including it in the dynamics constraint:

\begin{align}
  \minimize{x, u, \Delta t} \quad & \ell(x_N) \\
  \st \quad & f(x_{k+1}, x_k, u_k, \Delta t_k) = 0 \\
            & \Delta t^{\min} < \Delta t_k < \Delta t^{\max} \\
            & x_1 = x_{\text{init}} 
\end{align}

Here the time steps, $\Delta t_k$ are constrained to be within some reasonable bounds, $0 < \Delta t^{\min} < \Delta t^{\max}$, in order to prevent the solver from taking advantage of negative values and discretization error.   

\subsection{Minimum Time Problems}

Given a high fidelity, \textit{nominal} solution, $(x_{1:N}^{\text{nominal}}, u_{1:N-1}^{\text{nominal}}, \Delta t_{{1-N-1}})$, to the free time problem, we can warm start a new optimization problem where we seek to minimize the total time.  This problem can be set up as follows:

\begin{align}
  \minimize{x, u, \Delta t} \quad & \sum_{k=1}^{N-1} \Delta t_k \\
  \st \quad & f(x_{k+1}, x_k, u_k, \Delta t_k) = 0 \\
            & \Delta t^{\min} < \Delta t_k < \Delta t^{\max} \\
            & x_1 = x_{\text{init}} \\
            & x_N = x_N^{\text{nominal}}
\end{align}

Here we constrain the final state $x_N$ to equal the final state of the nominal trajectory---which can not be done with indirect methods---and forces the solver to find solutions that minimize the time objective without sacrificing the $\ell(x_T)$ objective.

\subsection{Summary}
Direct collocation allows us to solve QOC type problems in a way that overcomes the shortcomings of available indirect methods.  In this framework it is possible to solve a wide variety of trajectory optimization problems -- e.g., for an arbitrary non-linear objective $J(z)$, where $z = z_{1:N}$ is the collection of knot points at each time step, non-linear (or linear) constraints, abstractly written as $c(z) \in \mathcal{Z}$, where $\mathcal{Z}$ is the set of admissable values, we can write the following generalized direct collocation optimization problem:

\begin{align}
  \minimize{z} \quad & J(z) \\
  \st \quad & f(z_k, z_{k+1}) = 0 \\
            & c(z) \in \mathcal{Z} 
\end{align}

Here $f(z_{k+1}, z_k) = 0$ is the dynamics constraints generalized to knot points -- e.g, we might have $z_k = (x_k, u_k, \Delta t_k)^\top$ and $f(z_k, z_{k+1}) = f(x_{k+1}, x_k, u_k, \Delta t_k)$ along with $J(z) = J(x, u, \Delta t) = \ell(x_N)$. We write the problem in the form above, as it is the convention we have adopted in the corresponding software package: Pico.jl. 



\section{Quantum Control Problems}

This section deals with formulating QOC problems as direct collocation trajectory optimization problems as described in the previous section. A simple form of these types of problems is as follows:

\begin{align}
  \minimize{\psi, \vb{a}} \quad & J(\psi, \vb{a}) = \ell(\psi_N) = 1 - \abs{\braket{\psi_N}{\psi_{\text{goal}}}}^2 \\
  \st \quad & f(\psi_{k+1}, \psi_k, \vb{a}_k) = 0 \\
            & \psi_1 = \psi_{\text{init}} 
\end{align}



To implement this problem we must deal with a handful of quantum specific issues.  First we will cover how to convert to real values the complex valued states $\psi \in \mathbb{C}^n$ and Hamiltonians $H \in \mathbb{C}^{n \times n}$.  Next, we will discuss a novel, efficient way to enforce the dynamics, which naively requires a potentially very high dimensional matrix exponential. Finally we will discuss a few tricks for achieving certain types of solutions, such as \textit{bang-bang} solutions, \textit{smooth} solutions, and \textit{guard state} solutions. 




\subsection{Isomorphic Formulation}
To move between complex valued quantum states and real valued problem variables we will utilize the following isomorphic representations for complex vectors and matrices.  We will use \textit{tildes} to represent isomorphic representations from here on out. For the quantum states we then have

\begin{equation}
  \psi \in \mathbb{C}^n \quad \longrightarrow \quad \isopsi = \mqty(\Re \psi \\ \Im \psi) \in \mathbb{R}^{2n},
\end{equation}

\noindent
and for matrices we have

\begin{align}
  H \in \mathbb{C}^{n \times n} \quad \longrightarrow \quad \tilde{H} &= \mqty(\Re H & -\Im H \\ \Im H & \Re H) \in \mathbb{R}^{2n \times 2n}.
\end{align}

The Schr\"oedinger dynamics involve an evaluation of $\exp(-iH)$, so it will behoove us to define the following function $G$: 

\begin{equation}
  G(H) = \widetilde{-iH} = \mqty(\Im H & \Re H \\ -\Re H & \Im H) 
\end{equation}

\noindent
Which, as can be easily shown, aligns with the previous definition. Also, $G$ is a linear function of $H$ and $\vb{a} \in \mathbb{R}^m$, so we can then write 

\begin{equation}
  G(\vb{a}) = G(H(\vb{a})) = G_0 + \sum_j a^j G_j,
\end{equation}

\noindent
where $G_j := G(H_j)$ mnemonically represents the \textit{generator} of the dynamics.



\subsection{Pad\'e Integrator Dynamics}
Our dynamics can be precisely written in the form 

\begin{equation}
  f(\isopsi_{t+1}, \isopsi_t, \vb{a}_t) = \isopsi_{t+1} - \exp\qty(G(\vb{a}_t) \cdot \Delta t) \ \isopsi_t,
\end{equation}

\noindent
but this does not account for how matrix exponentials are actually computed numerically. A common approach is to use the Pad\'e approximant for the exponential,

\begin{equation}
  \exp(A) = \qty(I - \frac{1}{2} A + \frac{1}{9} A^2 + \dots)^{-1} \qty(I + \frac{1}{2} A + \frac{1}{9} A^2 + \dots),
\end{equation}

\noindent
and truncate the series at some order in the numerator and denominator.  

We take advantage of this structure by recognizing that in our framework the leading matrix inverse is computationally expensive and not necessary to compute directly --- we can simply shift it over; i.e., write

\begin{equation}
  f(\isopsi_{t+1}, \isopsi_t, \vb{a}_t) = \qty(I - \frac{\Delta t}{2} G + \frac{\Delta t^2}{9} G^2 + \dots) \isopsi_{t+1} - \qty(I + \frac{\Delta t}{2} G + \frac{\Delta t^2}{9} G^2 + \dots) \isopsi_t.
\end{equation}
\noindent
Here, $G = G(\vb{a}_t)$.

Given we can assume our dynamics model is not perfect and that numerical imprecision will arise regardless, it prompts us to lean toward efficiency. With these considerations we define the second and fourth order \textit{Pad\'e integrators} as 

\begin{align}
  \vb{P}^{(2)}(\isopsi_{t+1}, \isopsi_t, \vb{a}_t) &= \qty(I - \frac{\Delta t}{2} G(\vb{a}_t) ) \isopsi_{t+1} - \qty(I + \frac{\Delta t}{2} G(\vb{a}_t) ) \isopsi_t \\
  \vb{P}^{(4)}(\isopsi_{t+1}, \isopsi_t, \vb{a}_t) &= \qty(I - \frac{\Delta t}{2} G(\vb{a}_t)  + \frac{\Delta t^2}{9} G(\vb{a}_t) ^2) \isopsi_{t+1} - \qty(I + \frac{\Delta t}{2} G(\vb{a}_t)  + \frac{\Delta t^2}{9} G(\vb{a}_t) ^2) \isopsi_t
\end{align}

\subsection{Base Problem Definition}

Considering hardware limitations, where the pulse amplitude is limited to a finite range and where we must also have $\vb{a}_1 = \vb{a}_{N-1} = 0$, as well as numerical conditioning---for which we add a quadratic regulariztion term on the controls $\vb{a}_{1:N-1}$---we can now write the following constrained, isomorphic optimization problem, which will serve as the base problem we can build upon to achieve specific flavors of solutions:

\begin{align}
  \minimize{\isopsi, \vb{a}} \quad & J(\isopsi, \vb{a}) = \ell(\isopsi_N) + \sum_{k=1}^{N-1} \vb{a}_k^\top R \vb{a}_k \\
  \st \quad & \vb{P}^{(n)}(\isopsi_{k+1}, \isopsi_k, \vb{a}_k) = 0 \\
            & \isopsi_1 = \isopsi_{\text{init}} \\
            & \abs{a^j_k} \leq a_{\max}^j \\
            & \vb{a}_1 = \vb{a}_{N-1} = \vb{0} 
\end{align}

\noindent
\textbf{Remark:} In the following section, for brevity, we will omit the regularization term, as well as all of the above constraints except the dynamics from the problem definitions, but they should always be assumed to be present.



\section{Results}

\subsection{Solution Examples}

\subsubsection*{Base Problem Solutions}

\subsubsection*{Bang-Bang Solutions}

To achieve \textit{bang-bang} solution---in which the control is maxed out in one direction and then another---we can \textit{augment} the states of the problem and include the derivative of the controls, $\dot{\vb{a}}_k$, as the new control variable.  Putting an $L_1$ cost on the derivatives will then make it so the solver wants to zero out as many of the $\dot{\vb{a}}_k$'s as possible, giving us the type of solution we want. The new dynamics for this augmented problem are then

\begin{equation}
  \vb{f}(\isopsi_{k+1}, \vb{a}_{k+1}, \isopsi_k, \vb{a}_k, \dot{\vb{a}}_k) = \mqty(\vb{P}^{(n)}(\isopsi_{k+1}, \isopsi_k, \vb{a}_k) \\ \vb{a}_{k+1} - \vb{a}_k - \dot{\vb{a}}_k \cdot \Delta t).
\end{equation}

\noindent
This allows us to write the following problem:

\begin{align}
  \minimize{\isopsi, \vb{a}, \dot{\vb{a}}} \quad & J(\isopsi, \vb{a}, \dot{\vb{a}}) = \ell(\isopsi_N) + \sum_{k=1}^{N-1} \norm{\dot{\vb{a}}_k}_1 \\
  \st \quad & \vb{f}(\isopsi_{k+1}, \vb{a}_{k+1}, \isopsi_k, \vb{a}_k, \dot{\vb{a}}_k) = 0
\end{align}


\subsubsection*{Smooth Solutions}

\subsubsection*{Guard State Solutions}

\subsubsection*{Free Time Solutions}

\subsubsection*{Minimum Time Solutions}


\subsection{Comparison to Other Methods}

\subsection{Hardware Results}


\newpage


\end{document}