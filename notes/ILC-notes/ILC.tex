\documentclass{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{physics}
\usepackage[ruled]{algorithm2e}

\setlength{\parindent}{0pt}

\newcommand{\isopsi}{\tilde \psi}

\title{Iterative Learning Control with \\ Nonlinear Measurements}
\author{Aaron Trowbridge}
\date{}

\begin{document}

\maketitle

\section*{Setup}

Given a nominal state trajectory $\hat{x}(t)$ and control trajectory $u(t)$, we apply the controls to the experimental system and retrieve a set of measurements (abusing notation) $y(t)$ from the (possibly hidden) experimental trajectory $\bar x (t)$. Schematically we have:

$$
u(t) \longrightarrow \bar x (u(t), t) \longrightarrow g(\bar x(t), t) = \bar y(t)
$$

 
which coincides with the simplified model situation:

$$
u(t) \longrightarrow \hat x (u(t), t) \longrightarrow g(\hat x(t), t) = \hat y(t)
$$


We now have two sets of measurements: 

\begin{itemize}
  \item $\hat y(t)$ : the nominal measurement
  \item $\bar y(t)$ : the experimental measurement
\end{itemize}

\section*{Problem Formulation}

Let us write

$$
\bar x (t) = \hat x (t) + e(t)
$$


where $e(t)$ is the error in the experimental trajectory.  To correct for this error, we can find a correction term $\Delta x(t)$ s.t.

$$
g(\bar x + \Delta x) = g(\hat x + e + \Delta x ) = \hat y
$$

For example, if $g(x) = x$ is the identity function, i.e. we are trying to track the trajectory:

$$
\Delta x = -e 
$$

The real problem involves finding the corresponding correction to the controls: $\Delta u(t)$. This involves setting up a quadratic optimization problem.

\newpage
\subsection*{Quadratic Correction Problem}

The goal is now to go from the measurement error $\Delta y$ to a state correction $\Delta x$ and a control correction $\Delta u$ by simultaneously solving two linear systems.  Schematically:

$$
\Delta y \xrightarrow[g]{M \cdot \Delta x = \Delta y} \Delta x \xrightarrow[f]{D \cdot \Delta z = 0} \Delta u
$$

\subsubsection*{Measurement Correction to State Correction}

With $\Delta y \equiv \bar y - \hat y$, we have

\begin{align*}
  \bar y &= g(\bar x) \\
  &= g(\hat x + e) \\ 
  &\approx g(\hat x) + \pdv{g}{\hat x} \cdot e \\
  &= \hat y + \pdv{g}{\hat x} \cdot e  
\end{align*}

 
which, with writing $\hat M = \pdv*{g}{\hat x} $ yields

$$
\Delta y \approx \hat M \cdot e 
$$


and since $g: \mathbb{R}^n \to \mathbb{R}^m$ where $m \leq n$, $\hat M \in \mathbb{R}^{m \times n}$ is not necessarily invertible, but we can use the Moore-Penrose pseudoinverse here to get a guess for $e$:

$$
\boxed{
e \approx \hat M^+ \cdot \Delta y \equiv \hat e 
}
$$



To tie the experimental measurements to the model measurements we require 

\begin{align*}
\hat y &= g(\bar x + \Delta x) \\ 
&\approx \bar y + \pdv{g}{\bar x} \cdot \Delta x \\
&= \bar y + \bar M \cdot \Delta x
\end{align*}


which yields the condition

\begin{equation}
  \boxed{
  \bar M \cdot \Delta x = - \Delta y
  }
\end{equation}



where

\begin{align*}
  \bar M_i^j &= \partial g(\hat x + e)_i^j \\
  & \approx  \partial g(\hat x + \hat e)_i^j \\
  & \approx \partial g(\hat x)_i^j + \sum_k \qty(\partial^2 g(\hat x))_i^{jk} \ \hat e_k \\
  &= \hat M_i^j + \sum_{kl} \qty(\partial^2 g(\hat x))_i^{jk} \ \qty(\hat M^+)_k^l \Delta y_l 
\end{align*}

where 
$$
\partial g(\cdot) = \eval{\pdv{g}{x}}_{x = \cdot} 
$$

\subsubsection*{State Correction to Control Correction}

To propagate the state correction to the control correction, we utilize the dynamics constraint, $f(z_t, z_{t+1}) = 0$, where we define the \textit{knot point} 

$$
z_t =\mqty(x_t \\ u_t)
$$


Let's write $\vb{z}_t = \mqty(z_t \\ z_{t+1})$. Then we have

\begin{align*}
0 &= f( \hat{\vb{z}}_t + \Delta {\vb{z}}_t) \\
&\approx f(\hat{\vb{z}}_t) + \partial f(\hat{\vb{z}}_t) \cdot \Delta {\vb{z}}_t \\
\end{align*}


which yields, with $\hat D = \partial f(\hat{\vb{z}}_t)$

\begin{equation}
  \boxed{
  \hat D \cdot \Delta {\vb{z}}_t = 0
  }
\end{equation}


\subsubsection*{Putting it all together}

We seek to find the solution to

\begin{align*}
  \underset{\Delta x_{1:T},\ \Delta u_{1:T}}{\text{minimize}} & \quad \frac{1}{2} \sum_t \Delta x^\top_t Q \Delta x_t + \Delta u^\top_t R \Delta u_t \\
  \text{subject to} \ & 
  \quad \bar M \cdot \Delta x_\tau = - \Delta y_\tau \quad \forall \tau \\
  & \quad \hat D \cdot \Delta {\vb{z}}_t = 0 \quad \forall t
\end{align*}


where the $\tau$s are the measurement times.

\hfill


Building the KKT matrix from this problem, we can solve the system and extract $\Delta u(t)$ and repeat the procedure until convergence.

\hfill

This problem, which returns $\Delta Z$ is referred to as 

$$
\boxed{
\Delta Z = \textsf{QuadraticProblem}(\hat Z, \Delta Y)
}
$$

\subsubsection*{KKT Matrix (for just single quantum state and controls)}

Below we use:

\begin{itemize}
  \item $n = \dim z_t = \dim x_t + \dim u_t $ 
  \item $d = \dim x_t = \dim f(z_t, z_{t+1}) $ 
  \item $c = \dim u_t$  
  \item $m = \dim y_t$ 
  \item $M = \#\text{ of measurements}$
\end{itemize}



For a trajectory $Z = \text{vec}(z_{1:T})$, we need to construct the matrix

$$
\mqty(
  H & A^\top \\
  A & 0
)
$$


where $H$ is the Hessian of the cost function:

$$
H = \bigoplus_{t=1}^T \qty(Q \oplus R) = I^{T \times T} \otimes \qty(Q \oplus R)
$$


and $A$ is the constraint Jacobian:

$$
A = \mqty(
  \partial F \\
  \partial G
)
$$

with 

$$
\partial F = \mqty(
  \partial f(\hat{\vb{z}}_1) \\
  & \ddots \\
  & & \partial f(\hat{\vb{z}}_{T-1})
) \in \mathbb{R}^{d (T - 1) \times n T}
$$

and

$$
\partial G = \mqty(
  \ddots \\
  & \partial g(\bar x_{\tau}) \ \vb{0}^{m \times (a + c)} \\
  & & \ddots
) \in \mathbb{R}^{m M \times n T}
$$

where $\tau = t_1, \dots, t_M$ are the measurement times.

\hfill

For the constraints we then have

$$
\partial F \cdot \Delta Z = 0
\quad \text{and} \quad
\partial G \cdot \Delta Z = - \Delta Y
$$

where again

$$
\Delta Y = \bar Y - \hat Y
$$

\section*{An Alternative Quadratic Problem}

In the regime of noisy measurements, satisfying both the dynamics constraints and the measurement constraints becomes infeasible. To overcome this we we can relax the measurement into a maximum likelihood problem by assuming additive gaussian noise $w \sim \mathcal{N}(0, \Sigma)$.  To see this let's write

\begin{align*}
\bar y = \hat y - M \cdot \Delta x + w &\implies \bar y \sim \mathcal{N}(\hat y - M \cdot \Delta x, \Sigma) \\ 
&\implies \Delta y \sim \mathcal{N}(-M \cdot \Delta x, \Sigma) \\
\end{align*}

where $\Sigma$ is the covariance matrix of the measurement noise, which we can get from the experiment.  To make the following clearer, let's define the parameterized distribution over $\Delta y$ s.t. 

$$
\Delta y \sim p(\Delta x) = \mathcal{N}(-M \cdot \Delta x, \Sigma)
$$

then, given an observation $\bar y$, we can find the MLE for the parameter $\Delta x$ as the solution to the following optimization problem:

\begin{align*}
\max_{\Delta x} \ \log p(\Delta x) \ &\implies \ \min_{\Delta x} \ \frac{1}{2} \qty(\Delta y + M \cdot \Delta x)^\top \Sigma^{-1} \qty(\Delta y + M \cdot \Delta x) \\
&\implies \ \min_{\Delta x} \ \frac{1}{2} \Delta x^\top \qty(M^\top \Sigma^{-1} M) \Delta x + \qty(\Delta y^\top \Sigma^{-1} M) \Delta x 
\end{align*}

We can then augment our initial problem with this objective term and remove the measurement constraint.  This yields the following problem:

\begin{align*}
  \underset{\Delta x_{1:T},\ \Delta u_{1:T}}{\text{minimize}} & \quad \frac{1}{2} \sum_t \Delta x^\top_t Q \Delta x_t + \Delta u^\top_t R \Delta u_t \\
  & \quad + \sum_\tau \frac{1}{2} \Delta x_\tau^\top \qty(M_\tau^\top \Sigma^{-1} M_\tau) \Delta x_\tau + \qty(\Delta y_\tau^\top \Sigma^{-1} M_\tau) \Delta x_\tau \\
  \text{subject to} \ 
  & \quad \hat D \cdot \Delta {\vb{z}}_t = 0 \quad \forall t \\
  & \quad -u_\text{max} - \hat u_t < \Delta u_t < u_\text{max} - \hat u_t \\
  & \quad \Delta u_1 = \Delta u_T = 0
\end{align*}

\newpage

\section*{ILC Algorithm}

Tying everything together, \textit{iterative learning control} (ILC) solves the aforementioned quadratic problem and updates the trajectory iteratively until convergence.  The following algorithm codifies this: 

\begin{algorithm}
  \caption{Iterative Control Learning}
  \KwData{
    $\hat Z^\text{goal}$,
    $\textsf{tol} > 0$,
    $\alpha = 0.5$,
    $\beta = 0.1$,
}
  \KwResult{$U$}
  $Y^\text{goal} \gets \textsf{measure}(\hat Z^\text{goal}) = \text{vec}(y_{\tau_1:\tau_M})$\\
  $\hat Z \gets \hat Z^\text{goal}$\\
  $U \gets \textsf{controls}(\hat Z) = \text{vec}(u_{1:T})$ \\
  $\bar Y \gets \textsf{experiment}(U) = \text{vec}(\bar y_{\tau_1:\tau_M})$\\
  $\Delta Y \gets \bar Y - Y^\text{goal}$ \\
  $k \gets 1$\\
  \While{$\qty|\Delta Y| > \textsf{tol}$}{
    $\Delta Z \gets \beta \cdot \textsf{QuadraticProblem}(\hat Z, \Delta Y)$\\
    $\hat Z_{\text{next}} \gets \hat Z + \Delta Z $\\
    $\bar y_{T, \text{next}} \gets \textsf{measure\_final\_state}(\hat Z_{\text{next}})$\\
    $\Delta y_{T,\text{next}} \gets \bar y_{T, \text{next}} - \bar y_{T, \text{goal}}$\\
    
    \While{$\norm{\Delta y_{T,\text{next}}}_p > \norm{\Delta y_{T}}$\tcp*{Backtracking line search}}{
      $\Delta Z \gets \alpha \cdot \Delta Z$\\
      $\hat Z_{\text{next}} \gets \hat Z + \Delta Z $\\
      $\bar y_{T, \text{next}} \gets \textsf{measure\_final\_state}(\hat Z_{\text{next}})$\\
      $\Delta y_{T,\text{next}} \gets \bar y_{T, \text{next}} - \bar y_{T, \text{goal}}$\\
    } 
    $\hat Z \gets \hat Z_{\text{next}}$\\
    $U \gets \textsf{controls}(\hat Z)$\\
    $\bar Y \gets \textsf{experiment}(U)$\\
    $\Delta Y \gets \bar Y - Y^\text{goal}$\\
    $k \gets k + 1$\\
  }
  \Return{$U$}
\end{algorithm}


 
\end{document}